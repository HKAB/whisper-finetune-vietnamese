{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"checkpoint-epoch=0006.ckpt\", map_location=\"cpu\")['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all key of state_dict to remove \"model.\"\n",
    "new_state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = whisper.load_audio(\"/mnt/c/Users/truongnp3/Desktop/Course/NLP/Project/whisper-finetune-vietnamese/notebooks/test_audio.aiff\")\n",
    "# audio = whisper.load_audio(\"/mnt/c/Users/truongnp3/Downloads/spkyut-20190730-utt000005432.wav\")\n",
    "# audio = whisper.load_audio(\"/mnt/c/Users/truongnp3/Downloads/spkyut-20190730-utt000005394.wav\")\n",
    "audio = whisper.load_audio(\"/mnt/c/Users/truongnp3/Desktop/Course/NLP/Project/whisper-finetune-vietnamese/speed2text_demo/audio_folder/New Recording 4.m4a\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: vi\n"
     ]
    }
   ],
   "source": [
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions(fp16 = False, without_timestamps=True, language=\"vi\")\n",
    "# options = whisper.DecodingOptions(fp16 = False, withlm=False, beam_size=1, without_timestamps=True)\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "# print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuyên đẹp trai\n"
     ]
    }
   ],
   "source": [
    "print(result.text) #beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một hay bát bốn nắm.\n"
     ]
    }
   ],
   "source": [
    "print(result.text) #beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/hkab/dataset_tokenized_3gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# options = whisper.DecodingOptions(fp16 = False)\n",
    "options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=1, \n",
    "        patience=1.0, lm_path=\"dataset_tokenized_3gram.arpa\", lm_alpha=0.75, lm_beta=0.0,\n",
    "        without_timestamps=True)\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "# print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một hay bà bầu nắm.\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nhiều chồng ngờ góc quên hay góc xanh nhà, nhìn chọn chỗ đất hiện, đất cắt hoặc đất mùn, đất phủ xa tây sốt, đồ ẩm thấp, dễ phát nữ.\n",
    "\n",
    "- Nếu trồng ngờ góc quên hay góc xanh nhà, hiện trọn trộ đất hiện, đất cắt hoặc đất muồn, đất phủ xa tây sốt, đồ ẩm thấp, dễ phát nước."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "569cc53f83e70b41c2d959ffedb296ac14adb9e332ab59ae04a2c7a2935b0e00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
